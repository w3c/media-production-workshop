<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>The Production Metaverse - Steve Cronan - W3C/SMPTE Joint Workshop on Professional Media Production on the Web</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../talk-ui.css">
    <link rel="stylesheet" href="https://www.w3.org/2019/09/TPAC-template/fonts/iconmonstr-iconic-font.css">
    <meta name="twitter:site" content="@w3c">
    <meta name="twitter:card" content="summary_large_image">
    <meta property="og:title" content="The%20Production%20Metaverse by Steve%20Cronan%20(5th%20Kind)">
    <meta property="og:description" content="Modern%20productions%20are%20a%20collection%20of%20millions%20of%20files%20created%20by%20100s%20of%20users%20around%20the%20world%20to%20create%20a%20single%20piece%20of%20content%20surrounded%20by%20an%20array%20of%20marketing%2C%20licensing%20and%20distribution%20needs.%20In%20this%20talk%20i'll%20focus%20on%20how%20information%20moves%20throughout%20the%20creator%2Fproduction%2Fstudio%20ecosystem.%20The%20high%20velocity%20of%20files%20sizes%2C%20types%2C%20qualities%20all%20with%20Tier%201%20security%20requirements%20and%20real%20time%20review%20expectations%20create%20an%20interesting%20mix%20of%20challenges.">
    <meta property="og:image" content="thumbnails/steve-cronan-production-metaverse.jpg">
  </head>
  <body>
    <form id=form><!-- form to request a page in kiosk mode --></form>
    <header id="header" class="header">
      <div id="banner">
        <div>
          <p>
            <a href="https://www.w3.org/"><img alt="W3C" src=
            "../media/w3c_home_nb-v.svg" height="48" width="72"></a>
            <a href="https://www.smpte.org/"><img alt="SMPTE" src=
            "../media/smpte_logo.png" height="48"></a>
          </p>
          <div class="banner-title">
            <h1>
              W3C/SMPTE Joint Workshop on Professional Media Production on the Web
            </h1>
          </div>
          <p class="attribution">
            <span>Timeline photo by <a href="https://unsplash.com/@kineticbear?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jacob Miller</a> on <a href="https://unsplash.com/s/photos/timeline?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>
          </p>
          <p>9-18 November 2021; online event</p>
        </div>
      </div>
      <nav class="menu" id="menu">
        <ul>
          <li>
            <a href="../">Call for Participation</a>
          </li>
          <li>
            <a href="../talks.html">Talks</a>
          </li>
          <li>
            <a href="../speakers.html">Apply as a speaker</a>
          </li>
        </ul>
      </nav>
    </header>
    <main id="main" class="main talk">
      <section id="intro">
        <h2>The Production Metaverse</h2>

        <p class="talkinfo">
          Presenter: <strong>Steve Cronan (5th Kind)</strong><br>
          Duration: <strong>9 minutes</strong><br>
          Slides: <a href="null"><strong>PDF</strong></a>
        </p>

        <p class="buttons">
          <!-- previousStart -->
          <button form="form" type="submit" class="picto im-angle-left" formaction="pierre-anthony-lemieux-media-production.html">
            Previous: Lossless UHD videos in a browser
          </button>
          <!-- previousEnd -->
          <a href="../talks.html" class="picto im-data">All talks</a>
          <!-- nextStart -->
          <button form="form" type="submit" formaction="bruce-devlin-metadata.html">
            Next: Metadata in Production Workflows<span class="picto im-angle-right"></span>
          </button>
          <!-- nextEnd -->
        </p>
      </section>

      <section id="talk">
        <h3 style="display:none">Slides &amp; video</h3>

        <details>
          <summary>Keyboard shortcuts in the video player</summary>
          <ul>
            <li>Play/pause: <kbd>space</kbd>
            </li><li>Increase volume: <kbd>up arrow</kbd>
            </li><li>Decrease volume: <kbd>down arrow</kbd>
            </li><li>Seek forward: <kbd>right arrow</kbd>
            </li><li>Seek backward: <kbd>left arrow</kbd>
            </li><li>Captions on/off: <kbd>C</kbd>
            </li><li>Fullscreen on/off: <kbd>F</kbd>
            </li><li>Mute/unmute: <kbd>M</kbd>
            </li><li>Seek to 0%, 10%â€¦ 90%: <kbd>0-9</kbd>
          </li></ul>
        </details>

        <div id="player">
          <script type="application/ld+json">
            {
              "@context": "https://schema.org",
              "@type": "VideoObject",
              "name": "The Production Metaverse",
              "description": "Modern productions are a collection of millions of files created by 100s of users around the world to create a single piece of content surrounded by an array of marketing, licensing and distribution needs. In this talk i'll focus on how information moves throughout the creator/production/studio ecosystem. The high velocity of files sizes, types, qualities all with Tier 1 security requirements and real time review expectations create an interesting mix of challenges.",
              "thumbnailUrl": "thumbnails/steve-cronan-production-metaverse.jpg",
              "duration": "PT8M46S",
              "embedUrl": "https://iframe.videodelivery.net/eca8fa503ec7cc17f2b35724b10fe2ca",
            }
          </script>

          <iframe id="video" title="The%20Production%20Metaverse" src="https://iframe.videodelivery.net/eca8fa503ec7cc17f2b35724b10fe2ca"
            allow="accelerometer; autoplay; encrypted-media; picture-in-picture"
            allowfullscreen="" width="640" height="360" frameborder="0"></iframe>

          <div id="slides" class="fade-in" role="region" aria-live="off" aria-label="Slide container">
            <div>
  <p>From 5th Kind, and welcome to the production metaverse. Today, we're gonna walk through, what is the production metaverse? How is metadata used to orchestrate the pipeline of a studio and a production? What are some of the unique challenges? And how is it used in a virtual production across these studios?</p>
  <p>Just to start off with some of the foundation of what a production process looks like, it really starts with a script, the foundation of the story. From there you build out research, where you're pulling images from the web, you're building unique pieces of content with storyboards and concept art, you're doing scouting and location photos from around the world, set design with architectural drawings, casting with a whole range of other content.</p>
  <p>Then as you go into shooting, you're gonna be capturing all sorts of different resolutions at high frame rates, and potentially multiple cameras across multiple units in multiple locations. It's not uncommon for a production to generate hundreds of terabytes, if not petabytes, in a number of months, and require that all of that content be uploaded into the cloud, distributed out to multiple vendors, all working on that content in different ways and at different phases, and different needs for the production process.</p>
  <p>Editorial will then cut that all together and connect all those VFX vendors and all those VFX layers and elements that come together, and all the while feeding the marketing machine and the licensing machine up into the studio.</p>
  <p>As I said, the foundation really starts with the script. And what's interesting is a script is a structured document, you have scenes on the left, exterior, interior, day/night labels, story locations, characters, et cetera, all consistently structured in this document.</p>
  <p>Taking that foundation as we expand out from the story location into, say, the physical location of where is that set gonna be a shot, or are they gonna create it in a particular stage? You also have virtual elements with sequences and shots, so how's the visual effects department going to break down the information, and how does this all connect together into this actual production metaverse?</p>
  <p>Even going deeper into VFX, if you take, say, a particular shot, it's broken up into hundreds, if not thousands, of frames, and there's layers to those frames, maybe a foreground plate or a background plate. That foreground plate could be made up of models and rigs and textures, and combined with footage to come together just to create a couple of seconds of a beautiful image.</p>
  <p>And as an example, we could use maybe a foreground plate of a guy on a horse. Whack in a background layer, some smoke and some people and fire, I'll light it, color it, and you get this beautiful image. So if you can think of that happening thousands, if not tens of thousands of times across all of these millions of frames, thousands of shots and distributed globally to create this one piece of content and surrounding articles.</p>
  <p>So what's important is you get a consistent framework of how to structure that information from the file metadata, to how the files are structured within assets, the connective tissue of how a character is connected to an actor, leveraging AI analysis for automation of that as much as possible, connecting a shot to a vendor through external databases like File Maker, Ftrack or a shotgun database.</p>
  <p>How you pull in the pillars from all different phases of production from casting and pre-production to camera on set, to the editorial of post and the archive, all the way into the metaverse and into entities.</p>
  <p>So we leverage all this data to orchestrate the pipeline of status changes and triggering events for transcodes and file transfers with different applications in different events, all in the need of moving this data as fast as possible to give creatives as much time to make those decisions before they hit that deadline.</p>
  <p>That's one interesting thing about production is you've got a release date and the goal is how can you create the greatest film possible in that amount of time? So functionally our role is to help facilitate the orchestration, the speed of decisions, and creative flow as much as possible.</p>
  <p>And so some of the key challenges that we find through browsers is things like dealing with big file sizes and the need for UDP acceleration of large file transfers distributed globally around the world. When you've gotta be uploading many terabytes overnight, and it's required to be delivered in a location for that next artist to work on it, you just really need the robustness of commonly used tools like (?) and Asignet but to be able to get native support in the browser would be amazing.</p>
  <p>Upload folders, uploading folders, of course, many challenges there in a browser right now structured files, like a model that has a certain relationship to a rig and a texture maintaining those structures, commonly requires people to zip things up and then have them decompress on upload.</p>
  <p>Those robust transfers across a long haul globally distributed teams where you're shooting in New Zealand and your post house is in LA and the effects house is in the UK, et cetera, just being able to move data really fast is required, especially on location, the idea of sort of drop zones of how do you find that, a big pipe to get the data to where you need as fast as possible.</p>
  <p>And we also see a lot of duplication of files. You know, if there was the possibility of a client-side checksum where you would get a computable, a fingerprint, to realize you've already got that file in your system, because we're moving so many files around in different locations, just to be able to exchange a common hash, would just allow for a lot faster transfers with electric packet data.</p>
  <p>And editing, of course, the hybrid nature of being on prim, on location, in a studio, in the home, orchestrating that data, getting it to where it needs to be in a reasonable amount of time. You know, this is also driving the need to bring the desktop to the data or the desktop in the cloud. So accelerating the needs of common operating system and common applications to run directly in the cloud is accelerating. And a lot of challenges dealing with rural media costs, constantly requiring transcoding, very difficult to protect with any form of watermarking.</p>
  <p>Now with playback, we've seen a good evolution, obviously on the browsers, as we've seen many video technologies accelerate with fragmented MP4s and low-latency streaming live is accelerating across this industry right now, but the need for higher bit rates, higher fidelity 5.1 audio, et cetera, is definitely a higher requirement. You know, visual and forensic watermarking have always been the fundamentals of what we do.</p>
  <p>We used to be able to have a compiled container back in the days when flash was semi-secure and allowed you to have a DRM protected stream with the client side overlay that allowed you to leverage things like CDNs for optimize streaming. As we have lost that and WebAssembly has not really replaced it in its ability, from a security perspective, to create a secure container. It has required a lot of server-side watermarking to occur, which then of course creates more challenges with buffering.</p>
  <p>And VR 360 just being able to play that back with DRM, being able to maintain security as we move into more of these virtual worlds is gonna be critical.</p>
  <p>And then just for distribution, just offline tracking tends to come up a lot, the security, when things go offline, how can we keep some protection within the operating system or handoff between the browser and the operating system, being able to download folders so that you can maintain those structures, as we talked about the challenges on upload, and then just leveraging audio and AI analysis at scale, I think is going in the right direction and we'll be leveraging a lot more of that going forward.</p>
  <p>So I hope you found that useful, as you know, some of the pipelines and tools used in the orchestration of a studio and some of the challenges we run into and yeah, hopefully we can all work together to make it great. Have a good day.</p>
</div>


          </div>
        </div>
      </section>

      <section id="extrabuttons">
        <p class="buttons">
          <!-- previousStart -->
          <button form="form" id="prevtalk" type="submit" formaction="pierre-anthony-lemieux-media-production.html" class="picto im-angle-left">Previous: Lossless UHD videos in a browser</button>
          <!-- previousEnd -->
          <a id="alltalks" href="../talks.html" class="picto im-data">All talks</a>
          <!-- nextStart -->
          <button form="form" id="nexttalk" type="submit" formaction="bruce-devlin-metadata.html">Next: Metadata in Production Workflows<span class="picto im-angle-right"></span></button>
          <!-- nextEnd -->
        </p>
      </section>

      <section id="sponsors">
        <h2>
          Workshop sponsor
        </h2>
        <p><a href="https://www.adobe.com/"><img src="../media/adobe.png" alt="Adobe" width="70"></a></p>
        <p class="small">Interested in sponsoring the workshop?<br/>Please check the <a href="sponsors.html">sponsorship package</a>.</p>
      </section>
    </main>
    <footer class="footer" id="footer">
      <p>
        W3C is proud to be an open and inclusive organization, focused on
        productive discussions and actions. Our <a href=
        "https://www.w3.org/Consortium/cepc/">Code of Ethics and Professional
        Conduct</a> ensures that all voices can be heard.
      </p>
      <p>Questions? Contact FranÃ§ois Daoust
        &lt;<a href="mailto:fd@w3.org">fd@w3.org</a>&gt;.
      </p>
      <p>
        Suggestions for improving this workshop page, such as fixing typos or
        adding specific topics, can be made by opening a <a href=
        "https://github.com/w3c/media-production-workshop/">pull request on
        GitHub</a>, or by emailing FranÃ§ois Daoust
        &lt;<a href="mailto:fd@w3.org">fd@w3.org</a>&gt;.
      </p>
    </footer>
    <script src="../script.js"></script>
    <script>
      let captions = [
  {
    "language": "en",
    "label": "English",
    "src": "captions/steve-cronan-production-metaverse.vtt",
    "mode": "hidden",
    "cues": [],
    "activeCues": [
      {
        "text": ""
      }
    ]
  }
];
    </script>
    <script src="https://www.w3.org/2019/09/TPAC-template/parser.js"></script>
    <script src="https://embed.videodelivery.net/embed/sdk.latest.js"></script>
    <script src="../talk-sync.js"></script>
    <script src="https://w3c.github.io/i-slide/i-slide.js" type="module"></script>
  </body>
</html>
