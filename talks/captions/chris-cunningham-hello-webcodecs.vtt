WEBVTT

1
00:07.390 --> 00:08.890
<v ->Hi, I'm Chris Cunningham.</v>

2
00:08.890 --> 00:11.550
I am the tech lead for WebCodecs

3
00:11.550 --> 00:15.310
effort in Chrome and a co-editor on the spec.

4-p
00:15.310 --> 00:17.149
This talk is going to be a primer on the API.

5
00:17.149 --> 00:19.590
If you have already seen the API and played

6
00:19.590 --> 00:22.170
with it a little bit, or if you saw my talk

7
00:22.170 --> 00:25.120
at IIT earlier this week, you can skip this one.

8-p
00:25.120 --> 00:30.120
I am going to do a talk about video encoder configuration,

9
00:30.380 --> 00:32.820
and I do encourage everybody to check that one out.

10-p
00:32.820 --> 00:34.160
You're probably already familiar

11
00:34.160 --> 00:35.649
with existing codecs APIs,

12
00:35.649 --> 00:38.310
like ffmpeg, AVFoundation, MediaCodec,

13
00:38.310 --> 00:40.143
and WebCodecs is similar to those.

14-p
00:41.160 --> 00:44.730
Those libraries have been a dependency of the browser

15
00:44.730 --> 00:49.300
for years in support of the video tag and WebRTC.

16
00:49.300 --> 00:52.620
And with WebCodecs, we're exposing those and others

17
00:52.620 --> 00:55.253
in a unified manner directly to JavaScript.

slide-2
00:56.390 --> 00:59.408
Let's look at a typical decoder flow.

19-p
00:59.408 --> 01:03.973
In this graphic the large blue square is WebCodecs,

20
01:04.900 --> 01:07.550
and the diagram shows chunks of encoded video coming

21
01:07.550 --> 01:09.730
from network or storage, heading into

22
01:09.730 --> 01:12.890
the decoder, being decoded to these video frames,

23
01:12.890 --> 01:14.578
and then coming out where they are rendered to

24
01:14.578 --> 01:16.793
canvas or media stream track.

25-p
01:17.630 --> 01:20.700
We can use all these pieces together without writing

26
01:20.700 --> 01:21.960
a ton of code. And I think that's a

27
01:21.960 --> 01:22.867
good way to kind of get familiar with

28
01:22.867 --> 01:25.800
the API. Let's do that now.

slide-3
01:25.800 --> 01:29.830
I am going to share my screen, bear with me.

30
01:31.560 --> 01:33.700
Right.

31
01:33.700 --> 01:35.440
All right, so before I start coding, I want

32
01:35.440 --> 01:39.280
to show you what we're going to build.

33-p
01:39.280 --> 01:43.823
Big Buck Bunny, of course, being demuxed from an MP4 file,

34
01:43.823 --> 01:47.220
then decoded and rendered to canvas,

35
01:47.220 --> 01:49.330
all using WebCodecs.

36-p
01:51.280 --> 01:54.860
And I should point out that on the recording,

37
01:54.860 --> 01:57.500
it was just being done with Google Hangouts.

38
01:57.500 --> 01:59.354
You're probably seeing some stutter and some chop.

39
01:59.354 --> 02:04.354
And that is just the nature of recording using Hangouts.

40
02:04.721 --> 02:07.380
Locally, this is a smooth playback.

41
02:07.380 --> 02:09.300
Every frame is rendered. It's not being dropped.

42
02:09.300 --> 02:10.810
It's a little bit faster than

43
02:10.810 --> 02:12.670
the native playback rate for this file.

44
02:12.670 --> 02:14.600
And that's just because we're painting every frame as soon

45
02:14.600 --> 02:16.685
as it comes out of the decoder.

46-p
02:16.685 --> 02:18.450
Right.

47
02:18.450 --> 02:20.603
Let me show you where we are now.

48
02:21.633 --> 02:22.783
We have a blank canvas.

49
02:24.220 --> 02:25.470
Let's pull open the code.

50
02:27.230 --> 02:30.750
Alright. Like I said, we have a simple blank canvas

51
02:31.990 --> 02:34.720
and then I'm using MP4Box.js to do

52
02:34.720 --> 02:36.879
the demuxing of the MP4 file.

53
02:36.879 --> 02:37.843
That's why I'm pulling it here.

54-p
02:39.393 --> 02:40.780
And then we open up the script tag

55
02:40.780 --> 02:43.800
and I bring in an MP4 demuxer module,

56
02:43.800 --> 02:47.860
which is really just a wrapper around MP4Box.js.

57
02:47.860 --> 02:49.960
And there's some interesting stuff in there,

58
02:49.960 --> 02:52.240
but none of it really uses WebCodecs.

59
02:52.240 --> 02:53.580
I'm just gonna skip over it,

60
02:53.580 --> 02:55.284
and feel free to check it out on GitHub.

61-p
02:55.284 --> 02:59.670
All you need to know here is that it opens up the file for me

62
02:59.670 --> 03:02.800
and sort of populates the basic track info structure that

63
03:02.800 --> 03:04.520
I need telling me about width and height,

64
03:04.520 --> 03:08.270
and video, and it's codec details, etc.

65-p
03:08.270 --> 03:09.911
All right, then I grabbed the canvas element,

66
03:09.911 --> 03:13.660
set its dimensions according to what was found in the MP4.

67
03:13.660 --> 03:15.460
And I grabbed the context because I'm going

68
03:15.460 --> 03:19.230
to use that to paint video frames, shortly.

69-p
03:19.230 --> 03:21.733
Let's make a paintFrame function.

70
03:24.570 --> 03:27.610
All right, we're going to call it context.drawImage

71
03:27.610 --> 03:31.711
passing in frame at the origin

72
03:31.711 --> 03:36.711
and using the canvas width and height (inaudible.)

73-p
03:39.640 --> 03:41.590
Now that we're done rendering the frame,

74
03:41.590 --> 03:43.633
we're gonna call frame.close().

75-p
03:45.120 --> 03:46.710
A few things to talk about here.

76
03:46.710 --> 03:49.679
One, we were able to call drawImage like this

77
03:49.679 --> 03:52.979
because frame, VideoFrame, is a CanvasImageSource.

78
03:52.979 --> 03:54.122
And that means you can use it here,

79
03:54.122 --> 03:56.610
but also with a texImage2D, createImageBitmap

80
03:56.610 --> 04:00.200
anywhere that image source is accepted.

81-p
04:00.200 --> 04:02.751
Also we call frame.close() right away because

82
04:02.751 --> 04:05.450
we want to release the memory that

83
04:05.450 --> 04:08.470
backs that frame back to the browser

84
04:08.470 --> 04:13.391
for recycling and reuse. VideoFrame objects and

85
04:13.391 --> 04:16.460
the audio analog, which is called AudioData,

86
04:16.460 --> 04:18.772
are just lightweight JavaScript objects.

87
04:18.772 --> 04:22.110
But they hold references to heavier memory like,

88
04:22.110 --> 04:24.940
you know, actual pixel data or GPU buffers,

89
04:24.940 --> 04:27.760
typically pooled resources inside the browser.

90
04:27.760 --> 04:30.450
You want to call close on these objects as soon as you're

91
04:30.450 --> 04:33.282
done with them, so that the browser can reuse them,

92
04:33.282 --> 04:35.780
especially in the case of decoding because the decoder

93
04:35.780 --> 04:37.610
actually owns those pool resources.

94
04:37.610 --> 04:39.820
Returning them to the decoder prevents

95
04:39.820 --> 04:41.120
the decoder from stalling.

96-p
04:42.100 --> 04:42.933
Okay.

97
04:42.933 --> 04:46.127
We've got our paintFrame. Let's make a decoder.

98-p
04:51.270 --> 04:53.430
The constructor takes two callbacks.

99
04:53.430 --> 04:55.220
The first is an output callback,

100
04:55.220 --> 04:57.860
which we'll bring from above,

101
04:57.860 --> 04:59.930
the second is an error callback

102
04:59.930 --> 05:04.110
which you should use to do some kind of fallback handling,

103
05:04.110 --> 05:06.510
show a message to the user. In our case,

104
05:06.510 --> 05:09.993
this is just a demo, so, we'll just log it.

105-p
05:12.180 --> 05:13.130
All right.

106
05:13.880 --> 05:15.330
Now that we've got the decoder,

107
05:15.330 --> 05:16.633
we need to make a configuration.

108
05:17.800 --> 05:21.320
The required parameters here are going to be a codec string,

109
05:21.320 --> 05:24.510
which if you've used MediaSource or video canPlayType,

110
05:24.510 --> 05:25.450
MediaCapabilities,

111
05:25.450 --> 05:28.500
any of these APIs is the familiar codec string.

112
05:28.500 --> 05:29.910
For H264,

113
05:29.910 --> 05:34.513
this is a AVC1.1, profile bytes, level bytes.

114
05:35.930 --> 05:38.950
In our case, the demuxer has found those for us,

115
05:38.950 --> 05:41.513
so we're just going to call trackInfo.codec.

116-p
05:43.191 --> 05:45.230
But then we also need the description.

117
05:45.230 --> 05:46.910
If you are familiar with FFmpeg,

118
05:46.910 --> 05:50.370
this is the extradata. For those of you familiar with h.264

119
05:52.665 --> 05:55.450
and MP4 files, this is the AVCC atom.

120
05:56.556 --> 05:59.170
Generically, this is a

121
06:00.320 --> 06:01.210
sequence of codec

122
06:01.210 --> 06:03.540
specific bytes that is used to

123
06:03.540 --> 06:07.653
prepare the decoder for the stream that's about to decode.

124-p
06:08.500 --> 06:12.740
You can find more details about the description and the

125
06:12.740 --> 06:17.740
codec string in the codec registry in the WebCodecs spec.

126
06:18.400 --> 06:21.950
There we have the codec string for each codec and whether

127
06:21.950 --> 06:24.960
the description is required and if it is required,

128
06:24.960 --> 06:28.700
what its details are. In our case, like I said,

129
06:28.700 --> 06:29.230
it comes from the AVCC atom.

130
06:29.230 --> 06:32.710
The demuxer has already found it for us.

131
06:32.710 --> 06:34.600
I'll just plop it in there.

132-p
06:35.940 --> 06:37.940
All right, before we can use the configuration,

133
06:37.940 --> 06:40.853
we just check that the configuration is actually supported.

134
06:40.853 --> 06:45.853
Like any media API in the web support for a given codec,

135
06:46.700 --> 06:48.730
and the details of this configuration is going to vary by

136
06:48.730 --> 06:50.610
platform, by browser.

137
06:50.610 --> 06:53.630
It's important to first check before we try to use it.

138-p
06:53.630 --> 06:55.180
We're going to call

139
06:55.180 --> 06:58.271
VideoDecoder.isConfigSupported passing in the config.

140
06:58.271 --> 07:01.283
And then we're going to get the results of that.

141-p
07:04.570 --> 07:06.550
Here's where you would check: is it supported?

142
07:06.550 --> 07:08.560
And if not implement some sort of fallback plan,

143
07:08.560 --> 07:11.293
maybe you use WASM. Maybe you choose a different codec.

144
07:13.200 --> 07:14.200
This is a demo.

145
07:14.200 --> 07:19.200
I'm just going to say: assert that it is a supported.

146-p
07:21.100 --> 07:24.173
Okay, now that we know we can grab and configure the decoder.

147-p
07:29.750 --> 07:33.740
And now it's just time to start feeding the decoder with

148
07:33.740 --> 07:38.740
chunks to decode. We're going to say demuxer,

149
07:41.570 --> 07:43.993
give me the video stream, happens to be track zero,

150
07:44.970 --> 07:49.100
and then we're going to give a callback. For every chunk,

151
07:49.100 --> 07:53.480
please call decoder.decode, passing up that chunk.

152-p
07:53.480 --> 07:57.200
A few things to point out.

153
07:57.200 --> 08:00.410
There was no waiting here. When we called configure,

154
08:00.410 --> 08:02.300
we didn't wait for that to complete,

155
08:02.300 --> 08:04.860
before we started calling decode. When we called decode,

156
08:04.860 --> 08:06.660
We don't wait for the first decode to complete

157
08:06.660 --> 08:08.420
before we call the second decode.

158-p
08:08.420 --> 08:12.280
It's a fire and forget kind of a queued processing model

159
08:12.280 --> 08:13.490
under the hood.

160
08:13.490 --> 08:17.690
A decode that follows the configure is presumed to use

161
08:17.690 --> 08:20.967
the configuration that followed it in the configure.

162
08:20.967 --> 08:22.420
That preceded it in the configure.

163
08:22.420 --> 08:25.530
And then you can queue up as much work

164
08:25.530 --> 08:26.363
as you want.

165-p
08:27.220 --> 08:29.520
Alright, that should do it.

166
08:29.520 --> 08:31.193
Let's see if I have any typos.

167-p
08:32.640 --> 08:36.135
All right. There you have it, Big Buck Bunny,

168
08:36.135 --> 08:38.410
decoding and rendering.

slide-4
08:38.410 --> 08:40.910
We didn't talk at all about audio,

170
08:40.910 --> 08:41.860
but here in the slides,

171
08:41.860 --> 08:45.735
I'm going to link to the same demo basically,

172
08:45.735 --> 08:50.735
but with an audio playout that is synchronized to the video,

173
08:50.740 --> 08:54.439
and then this will also be a link to the GitHub code to make

174
08:54.439 --> 08:56.540
that work. The short of it is uses AdioDecoder,

175
08:56.540 --> 08:57.780
but instead of a canvas,

176
08:57.780 --> 09:00.510
you're going to use AudioWorklet to do the rendering.

177
09:00.510 --> 09:02.290
Just one option that you have,

178
09:02.290 --> 09:04.340
you could also use like AudioBufferSourceNode.

179
09:04.340 --> 09:05.959
If you're going to do, you know,

180
09:05.959 --> 09:08.590
just kind of like smaller chunks of audio, or MediaStreamTrack

181
09:08.590 --> 09:12.553
if you are doing kind of a real time scenario.

slide-5
09:13.831 --> 09:17.103
All right, let's talk a little bit about audio decoding.

183-p
09:19.640 --> 09:21.450
Here is the AudioDecoder interface.

184
09:21.450 --> 09:23.370
I didn't even show the VideoDecoder interface.

185
09:23.370 --> 09:24.998
They're basically the same.

186-p
09:24.998 --> 09:29.390
The things to point out are instead of outputting,

187
09:29.390 --> 09:30.500
a VideoFrame,

188
09:30.500 --> 09:33.580
AudioDecoder is going to output an AudioData object,

189
09:33.580 --> 09:35.979
which is conceptually just a buffer of PCM samples.

190
09:35.979 --> 09:40.700
Otherwise it's the same five methods, same two attributes,

191
09:40.700 --> 09:45.700
same constructor, you know, same semantics.

192-p
09:45.120 --> 09:47.350
Two methods we didn't get to when we talked about video,

193
09:47.350 --> 09:51.870
which are present in both interfaces are flush and reset.

194-p
09:51.870 --> 09:54.620
Flush is going to force the codec to flush the pipeline

195
09:54.620 --> 09:55.990
of all completed work.

196
09:55.990 --> 09:58.690
As it's going to admit any outputs that might've been ready,

197
09:58.690 --> 10:01.510
but haven't quite made it to the output callback yet.

198
10:01.510 --> 10:03.990
You might use this in an end of stream scenario where you

199
10:03.990 --> 10:06.330
have fed the decoder with all the things you need to give it,

200
10:06.330 --> 10:07.293
but you wanna make sure that you get

201
10:07.293 --> 10:09.770
like the last frame out.

202-p
10:09.770 --> 10:12.230
The other one that we didn't talk about is reset.

203
10:12.230 --> 10:14.470
Reset is going to completely reset the codec.

204
10:14.470 --> 10:17.904
It's going to drop all active work, all queued work.

205
10:17.904 --> 10:20.773
It's going to drop the active configuration,

206
10:20.773 --> 10:23.360
just everything.

207
10:23.360 --> 10:26.680
You would use this if you would do like a seek. And so,

208
10:26.680 --> 10:29.420
you know, the user said, you know, stop where you are.

209
10:29.420 --> 10:31.300
I'm going to go to this other point in the timeline,

210
10:31.300 --> 10:32.513
start there instead.

slide-6
10:34.330 --> 10:36.210
Okay. That was decoding.

212
10:36.210 --> 10:37.780
Let's talk a little bit about encoding.

213-p
10:37.780 --> 10:40.740
The flow is pretty much the same, but in reverse.

214
10:40.740 --> 10:45.670
Frames go in, they get encoded, they produce chunks.

215-p
10:45.670 --> 10:48.270
The encoder interfaces are nearly identical to those from

216
10:48.270 --> 10:51.120
decode. You swap decode for encode,

217
10:51.120 --> 10:53.360
but otherwise it's the same five methods you saw in the last

218
10:53.360 --> 10:54.310
slide.

219
10:54.310 --> 10:56.610
And then audio and coding also follows this exact same

220
10:56.610 --> 10:57.443
pattern.

slide-7
10:58.690 --> 10:59.523
At this point,

222
10:59.523 --> 11:01.530
you've had a glance at all the core interfaces and the

223
11:01.530 --> 11:05.600
relationships to each other.

224
11:05.600 --> 11:05.980
And that's kind of the gist.

225
11:05.980 --> 11:07.853
That's the primer on WebCodecs.

226
11:07.853 --> 11:08.960
As a reminder,

227
11:08.960 --> 11:10.500
I have another talk coming up for

228
11:10.500 --> 11:13.340
VideoEncoder configuration,

229
11:13.340 --> 11:14.440
please check that out.
